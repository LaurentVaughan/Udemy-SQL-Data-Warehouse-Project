{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e09e258",
   "metadata": {},
   "source": [
    "# Test Suite: public.etl_config Configuration Table\n",
    "\n",
    "**Purpose:** Validate the structure, seeding, and behavior of `public.etl_config` table\n",
    "\n",
    "**Scope:**\n",
    "- Table existence and schema placement\n",
    "- Column definitions (names, types, constraints)\n",
    "- Required configuration keys are seeded\n",
    "- Path convention compliance (no trailing slashes)\n",
    "- Idempotency of re-runs\n",
    "- Primary key constraint enforcement\n",
    "\n",
    "**Testing Strategy:**\n",
    "- Structural validation (table, columns, constraints)\n",
    "- Data validation (required keys, value formats)\n",
    "- Behavioral testing (idempotency, conflict handling)\n",
    "- Integration testing (path resolution)\n",
    "\n",
    "**Prerequisites:**\n",
    "- Database connection configured\n",
    "- `setup/seed/01_etl_config.sql` has been executed\n",
    "- Required packages: psycopg2, pytest, ipytest, pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2873d3a6",
   "metadata": {},
   "source": [
    "## Setup: Import Dependencies & Configure Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e75cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import psycopg2\n",
    "from psycopg2 import sql\n",
    "import pytest\n",
    "import ipytest\n",
    "import pandas as pd\n",
    "\n",
    "# Configure ipytest for notebook usage\n",
    "ipytest.autoconfig()\n",
    "\n",
    "# Database connection parameters\n",
    "DB_CONFIG = {\n",
    "    'host': 'localhost',\n",
    "    'database': 'sql_retail_analytics_warehouse',\n",
    "    'user': 'postgres',\n",
    "    'password': os.getenv('POSTGRES_PASSWORD', 'your_password_here')\n",
    "}\n",
    "\n",
    "print(\"‚úÖ Dependencies imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68258a07",
   "metadata": {},
   "source": [
    "## Fixtures: Database Connection & Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d9bf85",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pytest.fixture(scope='module')\n",
    "def db_connection():\n",
    "    \"\"\"Create a database connection for tests.\"\"\"\n",
    "    conn = psycopg2.connect(**DB_CONFIG)\n",
    "    conn.autocommit = True\n",
    "    yield conn\n",
    "    conn.close()\n",
    "\n",
    "@pytest.fixture(scope='module')\n",
    "def db_cursor(db_connection):\n",
    "    \"\"\"Create a cursor for executing queries.\"\"\"\n",
    "    cursor = db_connection.cursor()\n",
    "    yield cursor\n",
    "    cursor.close()\n",
    "\n",
    "print(\"‚úÖ Fixtures defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413297a7",
   "metadata": {},
   "source": [
    "## Test Suite 1: Table Structure Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa34216",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ipytest\n",
    "\n",
    "def test_etl_config_table_exists(db_cursor):\n",
    "    \"\"\"Verify public.etl_config table exists.\"\"\"\n",
    "    db_cursor.execute(\"\"\"\n",
    "        SELECT COUNT(*) \n",
    "        FROM information_schema.tables \n",
    "        WHERE table_schema = 'public' \n",
    "          AND table_name = 'etl_config'\n",
    "    \"\"\")\n",
    "    count = db_cursor.fetchone()[0]\n",
    "    assert count == 1, \"public.etl_config table must exist\"\n",
    "\n",
    "def test_etl_config_in_public_schema(db_cursor):\n",
    "    \"\"\"Verify table is in public schema, not other schemas.\"\"\"\n",
    "    db_cursor.execute(\"\"\"\n",
    "        SELECT table_schema\n",
    "        FROM information_schema.tables \n",
    "        WHERE table_name = 'etl_config'\n",
    "    \"\"\")\n",
    "    result = db_cursor.fetchone()\n",
    "    assert result is not None, \"etl_config table not found\"\n",
    "    assert result[0] == 'public', \"etl_config must be in public schema\"\n",
    "\n",
    "def test_etl_config_column_count(db_cursor):\n",
    "    \"\"\"Verify table has exactly 2 columns.\"\"\"\n",
    "    db_cursor.execute(\"\"\"\n",
    "        SELECT COUNT(*) \n",
    "        FROM information_schema.columns \n",
    "        WHERE table_schema = 'public' \n",
    "          AND table_name = 'etl_config'\n",
    "    \"\"\")\n",
    "    count = db_cursor.fetchone()[0]\n",
    "    assert count == 2, \"etl_config should have exactly 2 columns (config_key, config_value)\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52fb56a7",
   "metadata": {},
   "source": [
    "## Test Suite 2: Column Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33ac157",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ipytest\n",
    "\n",
    "def test_etl_config_column_definitions(db_cursor):\n",
    "    \"\"\"Verify column names, types, and nullability.\"\"\"\n",
    "    db_cursor.execute(\"\"\"\n",
    "        SELECT \n",
    "            column_name,\n",
    "            data_type,\n",
    "            character_maximum_length,\n",
    "            is_nullable\n",
    "        FROM information_schema.columns\n",
    "        WHERE table_schema = 'public'\n",
    "          AND table_name = 'etl_config'\n",
    "        ORDER BY ordinal_position\n",
    "    \"\"\")\n",
    "    \n",
    "    columns = db_cursor.fetchall()\n",
    "    column_dict = {\n",
    "        col[0]: {\n",
    "            'type': col[1], \n",
    "            'max_length': col[2], \n",
    "            'nullable': col[3]\n",
    "        } for col in columns\n",
    "    }\n",
    "    \n",
    "    # Expected: config_key VARCHAR(100) PRIMARY KEY (NOT NULL)\n",
    "    assert 'config_key' in column_dict, \"config_key column must exist\"\n",
    "    assert column_dict['config_key']['type'] == 'character varying', \\\n",
    "        \"config_key should be VARCHAR\"\n",
    "    assert column_dict['config_key']['max_length'] == 100, \\\n",
    "        \"config_key should have max length 100\"\n",
    "    assert column_dict['config_key']['nullable'] == 'NO', \\\n",
    "        \"config_key should be NOT NULL (primary key)\"\n",
    "    \n",
    "    # Expected: config_value VARCHAR(200) NOT NULL\n",
    "    assert 'config_value' in column_dict, \"config_value column must exist\"\n",
    "    assert column_dict['config_value']['type'] == 'character varying', \\\n",
    "        \"config_value should be VARCHAR\"\n",
    "    assert column_dict['config_value']['max_length'] == 200, \\\n",
    "        \"config_value should have max length 200\"\n",
    "    assert column_dict['config_value']['nullable'] == 'NO', \\\n",
    "        \"config_value should be NOT NULL\"\n",
    "\n",
    "def test_etl_config_primary_key(db_cursor):\n",
    "    \"\"\"Verify config_key is the primary key.\"\"\"\n",
    "    db_cursor.execute(\"\"\"\n",
    "        SELECT a.attname\n",
    "        FROM pg_index i\n",
    "        JOIN pg_attribute a ON a.attrelid = i.indrelid AND a.attnum = ANY(i.indkey)\n",
    "        WHERE i.indrelid = 'public.etl_config'::regclass\n",
    "          AND i.indisprimary\n",
    "    \"\"\")\n",
    "    pk_columns = [row[0] for row in db_cursor.fetchall()]\n",
    "    assert pk_columns == ['config_key'], \"Primary key should be 'config_key' only\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ec5d5e",
   "metadata": {},
   "source": [
    "## Test Suite 3: Seeded Configuration Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591d0dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ipytest\n",
    "\n",
    "def test_required_config_keys_exist(db_cursor):\n",
    "    \"\"\"Verify both required configuration keys are seeded.\"\"\"\n",
    "    db_cursor.execute(\"\"\"\n",
    "        SELECT config_key\n",
    "        FROM public.etl_config\n",
    "        WHERE config_key IN ('base_path_crm', 'base_path_erp')\n",
    "        ORDER BY config_key\n",
    "    \"\"\")\n",
    "    \n",
    "    keys = [row[0] for row in db_cursor.fetchall()]\n",
    "    assert 'base_path_crm' in keys, \"base_path_crm must be seeded\"\n",
    "    assert 'base_path_erp' in keys, \"base_path_erp must be seeded\"\n",
    "    assert len(keys) == 2, \"Exactly 2 required keys should be present\"\n",
    "\n",
    "def test_config_values_not_null_or_empty(db_cursor):\n",
    "    \"\"\"Verify all config values are non-NULL and non-empty.\"\"\"\n",
    "    db_cursor.execute(\"\"\"\n",
    "        SELECT config_key, config_value\n",
    "        FROM public.etl_config\n",
    "        WHERE config_value IS NULL \n",
    "           OR TRIM(config_value) = ''\n",
    "    \"\"\")\n",
    "    \n",
    "    invalid_entries = db_cursor.fetchall()\n",
    "    assert len(invalid_entries) == 0, \\\n",
    "        f\"Found config keys with NULL or empty values: {invalid_entries}\"\n",
    "\n",
    "def test_config_values_are_valid_paths(db_cursor):\n",
    "    \"\"\"Verify config values look like valid file paths.\"\"\"\n",
    "    db_cursor.execute(\"\"\"\n",
    "        SELECT config_key, config_value\n",
    "        FROM public.etl_config\n",
    "        WHERE config_key IN ('base_path_crm', 'base_path_erp')\n",
    "    \"\"\")\n",
    "    \n",
    "    for key, value in db_cursor.fetchall():\n",
    "        # Should contain path separators\n",
    "        assert ('/' in value or '\\\\' in value), \\\n",
    "            f\"{key} value '{value}' doesn't look like a file path\"\n",
    "        # Should not be just a separator\n",
    "        assert len(value.strip('/\\\\')) > 0, \\\n",
    "            f\"{key} value '{value}' is invalid\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf116f15",
   "metadata": {},
   "source": [
    "## Test Suite 4: Path Convention Compliance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d8814a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ipytest\n",
    "\n",
    "def test_no_trailing_slashes_in_paths(db_cursor):\n",
    "    \"\"\"Verify CRITICAL requirement: no trailing slashes in file paths.\"\"\"\n",
    "    db_cursor.execute(\"\"\"\n",
    "        SELECT config_key, config_value\n",
    "        FROM public.etl_config\n",
    "        WHERE config_key IN ('base_path_crm', 'base_path_erp')\n",
    "    \"\"\")\n",
    "    \n",
    "    for key, value in db_cursor.fetchall():\n",
    "        assert not value.endswith('/'), \\\n",
    "            f\"{key} has trailing forward slash: '{value}' (VIOLATION: must not end with /)\"\n",
    "        assert not value.endswith('\\\\'), \\\n",
    "            f\"{key} has trailing backslash: '{value}' (VIOLATION: must not end with \\\\)\"\n",
    "\n",
    "def test_paths_use_forward_slashes(db_cursor):\n",
    "    \"\"\"Verify paths use forward slashes (cross-platform compatibility).\"\"\"\n",
    "    db_cursor.execute(\"\"\"\n",
    "        SELECT config_key, config_value\n",
    "        FROM public.etl_config\n",
    "        WHERE config_key IN ('base_path_crm', 'base_path_erp')\n",
    "    \"\"\")\n",
    "    \n",
    "    for key, value in db_cursor.fetchall():\n",
    "        # Should use forward slashes (PostgreSQL/cross-platform standard)\n",
    "        assert '/' in value, f\"{key} should use forward slashes: '{value}'\"\n",
    "        # Warn if backslashes are present (Windows-specific)\n",
    "        if '\\\\' in value:\n",
    "            print(f\"‚ö†Ô∏è  Warning: {key} contains backslashes: '{value}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55c94aa",
   "metadata": {},
   "source": [
    "## Test Suite 5: Idempotency & Conflict Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc255b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ipytest\n",
    "\n",
    "def test_idempotent_rerun_no_duplicates(db_cursor):\n",
    "    \"\"\"Verify re-running INSERT with ON CONFLICT doesn't create duplicates.\"\"\"\n",
    "    # Count before\n",
    "    db_cursor.execute(\"\"\"\n",
    "        SELECT COUNT(*) FROM public.etl_config\n",
    "        WHERE config_key IN ('base_path_crm', 'base_path_erp')\n",
    "    \"\"\")\n",
    "    count_before = db_cursor.fetchone()[0]\n",
    "    \n",
    "    # Re-run the INSERT (should do nothing due to ON CONFLICT)\n",
    "    db_cursor.execute(\"\"\"\n",
    "        INSERT INTO public.etl_config (config_key, config_value)\n",
    "        VALUES\n",
    "          ('base_path_crm', 'dummy_path_1'),\n",
    "          ('base_path_erp', 'dummy_path_2')\n",
    "        ON CONFLICT (config_key) DO NOTHING\n",
    "    \"\"\")\n",
    "    \n",
    "    # Count after\n",
    "    db_cursor.execute(\"\"\"\n",
    "        SELECT COUNT(*) FROM public.etl_config\n",
    "        WHERE config_key IN ('base_path_crm', 'base_path_erp')\n",
    "    \"\"\")\n",
    "    count_after = db_cursor.fetchone()[0]\n",
    "    \n",
    "    assert count_before == count_after, \\\n",
    "        f\"Idempotency violated: count changed from {count_before} to {count_after}\"\n",
    "\n",
    "def test_existing_values_preserved_on_conflict(db_cursor):\n",
    "    \"\"\"Verify ON CONFLICT DO NOTHING preserves existing values.\"\"\"\n",
    "    # Get original values\n",
    "    db_cursor.execute(\"\"\"\n",
    "        SELECT config_key, config_value\n",
    "        FROM public.etl_config\n",
    "        WHERE config_key IN ('base_path_crm', 'base_path_erp')\n",
    "        ORDER BY config_key\n",
    "    \"\"\")\n",
    "    original_values = {row[0]: row[1] for row in db_cursor.fetchall()}\n",
    "    \n",
    "    # Attempt to insert different values (should be ignored)\n",
    "    db_cursor.execute(\"\"\"\n",
    "        INSERT INTO public.etl_config (config_key, config_value)\n",
    "        VALUES\n",
    "          ('base_path_crm', 'THIS_SHOULD_BE_IGNORED'),\n",
    "          ('base_path_erp', 'THIS_SHOULD_ALSO_BE_IGNORED')\n",
    "        ON CONFLICT (config_key) DO NOTHING\n",
    "    \"\"\")\n",
    "    \n",
    "    # Verify values unchanged\n",
    "    db_cursor.execute(\"\"\"\n",
    "        SELECT config_key, config_value\n",
    "        FROM public.etl_config\n",
    "        WHERE config_key IN ('base_path_crm', 'base_path_erp')\n",
    "        ORDER BY config_key\n",
    "    \"\"\")\n",
    "    current_values = {row[0]: row[1] for row in db_cursor.fetchall()}\n",
    "    \n",
    "    assert original_values == current_values, \\\n",
    "        \"ON CONFLICT DO NOTHING failed to preserve existing values\"\n",
    "\n",
    "def test_primary_key_constraint_enforced(db_cursor):\n",
    "    \"\"\"Verify primary key prevents duplicate keys without ON CONFLICT.\"\"\"\n",
    "    from psycopg2 import errors\n",
    "    \n",
    "    with pytest.raises(errors.UniqueViolation):\n",
    "        db_cursor.execute(\"\"\"\n",
    "            INSERT INTO public.etl_config (config_key, config_value)\n",
    "            VALUES ('base_path_crm', 'duplicate_attempt')\n",
    "        \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318408d5",
   "metadata": {},
   "source": [
    "## Test Suite 6: Integration - Path Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9a006a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ipytest\n",
    "\n",
    "def test_path_construction_no_double_slashes(db_cursor):\n",
    "    \"\"\"Verify path concatenation doesn't create double slashes.\"\"\"\n",
    "    db_cursor.execute(\"\"\"\n",
    "        SELECT \n",
    "            config_key,\n",
    "            config_value,\n",
    "            config_value || '/' || 'test_file.csv' AS full_path\n",
    "        FROM public.etl_config\n",
    "        WHERE config_key IN ('base_path_crm', 'base_path_erp')\n",
    "    \"\"\")\n",
    "    \n",
    "    for key, base_path, full_path in db_cursor.fetchall():\n",
    "        assert '//' not in full_path, \\\n",
    "            f\"{key}: Path construction created double slash: '{full_path}'\"\n",
    "        assert full_path.endswith('test_file.csv'), \\\n",
    "            f\"{key}: Path construction failed: '{full_path}'\"\n",
    "\n",
    "def test_realistic_file_path_construction(db_cursor):\n",
    "    \"\"\"Test path construction with realistic filenames.\"\"\"\n",
    "    test_files = ['cust_info.csv', 'prd_info.csv', 'CUST_AZ12.csv']\n",
    "    \n",
    "    db_cursor.execute(\"\"\"\n",
    "        SELECT config_value\n",
    "        FROM public.etl_config\n",
    "        WHERE config_key = 'base_path_crm'\n",
    "    \"\"\")\n",
    "    base_path = db_cursor.fetchone()[0]\n",
    "    \n",
    "    for filename in test_files:\n",
    "        full_path = f\"{base_path}/{filename}\"\n",
    "        assert '//' not in full_path, f\"Double slash in: {full_path}\"\n",
    "        assert full_path.endswith(filename), f\"Filename lost: {full_path}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565c2386",
   "metadata": {},
   "source": [
    "## Test Suite 7: Data Integrity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c05dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ipytest\n",
    "\n",
    "def test_no_duplicate_keys(db_cursor):\n",
    "    \"\"\"Verify no duplicate config_key values exist.\"\"\"\n",
    "    db_cursor.execute(\"\"\"\n",
    "        SELECT config_key, COUNT(*)\n",
    "        FROM public.etl_config\n",
    "        GROUP BY config_key\n",
    "        HAVING COUNT(*) > 1\n",
    "    \"\"\")\n",
    "    \n",
    "    duplicates = db_cursor.fetchall()\n",
    "    assert len(duplicates) == 0, f\"Found duplicate keys: {duplicates}\"\n",
    "\n",
    "def test_config_key_case_sensitivity(db_cursor):\n",
    "    \"\"\"Verify config keys use consistent casing convention.\"\"\"\n",
    "    db_cursor.execute(\"\"\"\n",
    "        SELECT config_key\n",
    "        FROM public.etl_config\n",
    "        WHERE config_key IN ('base_path_crm', 'base_path_erp')\n",
    "    \"\"\")\n",
    "    \n",
    "    keys = [row[0] for row in db_cursor.fetchall()]\n",
    "    for key in keys:\n",
    "        # Verify lowercase with underscores (snake_case)\n",
    "        assert key == key.lower(), f\"Key '{key}' should be lowercase\"\n",
    "        assert ' ' not in key, f\"Key '{key}' should not contain spaces\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1961e84a",
   "metadata": {},
   "source": [
    "## Summary: Run All Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0b9e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run all tests in this notebook\n",
    "ipytest.run('-v')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c17d0e",
   "metadata": {},
   "source": [
    "## Manual Inspection: View Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b289fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect and display current configuration\n",
    "conn = psycopg2.connect(**DB_CONFIG)\n",
    "\n",
    "# View all configuration entries\n",
    "df_config = pd.read_sql(\"\"\"\n",
    "    SELECT \n",
    "        config_key,\n",
    "        config_value,\n",
    "        LENGTH(config_value) AS value_length,\n",
    "        CASE \n",
    "            WHEN config_value LIKE '%/' THEN '‚ùå Has trailing slash'\n",
    "            ELSE '‚úÖ No trailing slash'\n",
    "        END AS path_check\n",
    "    FROM public.etl_config\n",
    "    ORDER BY config_key\n",
    "\"\"\", conn)\n",
    "\n",
    "print(\"\\nüìã Current Configuration:\")\n",
    "display(df_config)\n",
    "\n",
    "# View table structure\n",
    "df_structure = pd.read_sql(\"\"\"\n",
    "    SELECT \n",
    "        column_name,\n",
    "        data_type,\n",
    "        character_maximum_length,\n",
    "        is_nullable,\n",
    "        column_default\n",
    "    FROM information_schema.columns\n",
    "    WHERE table_schema = 'public'\n",
    "      AND table_name = 'etl_config'\n",
    "    ORDER BY ordinal_position\n",
    "\"\"\", conn)\n",
    "\n",
    "print(\"\\nüèóÔ∏è  Table Structure:\")\n",
    "display(df_structure)\n",
    "\n",
    "# View constraints\n",
    "df_constraints = pd.read_sql(\"\"\"\n",
    "    SELECT \n",
    "        conname AS constraint_name,\n",
    "        CASE contype\n",
    "            WHEN 'p' THEN 'PRIMARY KEY'\n",
    "            WHEN 'f' THEN 'FOREIGN KEY'\n",
    "            WHEN 'u' THEN 'UNIQUE'\n",
    "            WHEN 'c' THEN 'CHECK'\n",
    "            ELSE contype::text\n",
    "        END AS constraint_type,\n",
    "        pg_get_constraintdef(oid) AS definition\n",
    "    FROM pg_constraint\n",
    "    WHERE conrelid = 'public.etl_config'::regclass\n",
    "    ORDER BY conname\n",
    "\"\"\", conn)\n",
    "\n",
    "print(\"\\nüîí Constraints:\")\n",
    "display(df_constraints)\n",
    "\n",
    "conn.close()\n",
    "print(\"\\n‚úÖ Inspection complete\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

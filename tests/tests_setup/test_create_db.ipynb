{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12320785",
   "metadata": {},
   "source": [
    "# Test Suite: Database Creation and Configuration\n",
    "\n",
    "**Purpose:** Validate the sql_retail_analytics_warehouse database creation and configuration\n",
    "\n",
    "**Scope:**\n",
    "- Database existence and naming\n",
    "- Encoding configuration (UTF-8)\n",
    "- Locale settings (en_GB.UTF-8)\n",
    "- Template configuration\n",
    "- Ownership and privileges\n",
    "- Connection validation\n",
    "\n",
    "**Testing Strategy:**\n",
    "- Existence validation (database created successfully)\n",
    "- Configuration validation (encoding, collation, ctype)\n",
    "- Ownership validation (correct owner assigned)\n",
    "- Connection testing (can establish connections)\n",
    "- Isolation testing (clean template, no extra objects)\n",
    "\n",
    "**Prerequisites:**\n",
    "- PostgreSQL server running\n",
    "- `setup/create_db.sql` has been executed\n",
    "- Connection credentials available\n",
    "- Required packages: psycopg2, pytest, ipytest, pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3044c638",
   "metadata": {},
   "source": [
    "## Setup: Import Dependencies & Configure Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb006979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dependencies imported successfully\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import psycopg2\n",
    "from psycopg2 import sql\n",
    "from psycopg2.extensions import ISOLATION_LEVEL_AUTOCOMMIT\n",
    "import pytest\n",
    "import ipytest\n",
    "import pandas as pd\n",
    "\n",
    "# Configure ipytest for notebook usage\n",
    "ipytest.autoconfig()\n",
    "\n",
    "# Database connection parameters\n",
    "DB_CONFIG = {\n",
    "    'host': 'localhost',\n",
    "    'user': 'postgres',\n",
    "    'password': os.getenv('POSTGRES_PASSWORD', 'your_password_here')\n",
    "}\n",
    "\n",
    "# Target database name\n",
    "TARGET_DB = 'sql_retail_analytics_warehouse'\n",
    "\n",
    "print(\"✅ Dependencies imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e33715",
   "metadata": {},
   "source": [
    "## Fixtures: Database Connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24bb509a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fixtures defined\n"
     ]
    }
   ],
   "source": [
    "@pytest.fixture(scope='module')\n",
    "def postgres_connection():\n",
    "    \"\"\"Connection to postgres database for catalog queries.\"\"\"\n",
    "    conn = psycopg2.connect(database='postgres', **DB_CONFIG)\n",
    "    conn.autocommit = True\n",
    "    yield conn\n",
    "    conn.close()\n",
    "\n",
    "@pytest.fixture(scope='module')\n",
    "def postgres_cursor(postgres_connection):\n",
    "    \"\"\"Cursor for postgres database.\"\"\"\n",
    "    cursor = postgres_connection.cursor()\n",
    "    yield cursor\n",
    "    cursor.close()\n",
    "\n",
    "@pytest.fixture(scope='module')\n",
    "def target_connection():\n",
    "    \"\"\"Connection to target warehouse database.\"\"\"\n",
    "    conn = psycopg2.connect(database=TARGET_DB, **DB_CONFIG)\n",
    "    conn.autocommit = True\n",
    "    yield conn\n",
    "    conn.close()\n",
    "\n",
    "@pytest.fixture(scope='module')\n",
    "def target_cursor(target_connection):\n",
    "    \"\"\"Cursor for target database.\"\"\"\n",
    "    cursor = target_connection.cursor()\n",
    "    yield cursor\n",
    "    cursor.close()\n",
    "\n",
    "print(\"✅ Fixtures defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3610f2e",
   "metadata": {},
   "source": [
    "## Test Suite 1: Database Existence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63fcdcd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m======================================= test session starts =======================================\u001b[0m\n",
      "platform win32 -- Python 3.12.4, pytest-8.4.2, pluggy-1.6.0 -- c:\\Users\\Laurent\\Studies\\sql-ultimate-course\\Udemy-SQL-Data-Warehouse-Project\\.venv\\Scripts\\python.exe\n",
      "cachedir: .pytest_cache\n",
      "rootdir: c:\\Users\\Laurent\\Studies\\sql-ultimate-course\\Udemy-SQL-Data-Warehouse-Project\\tests\\tests_setup\n",
      "plugins: anyio-4.11.0, nbmake-1.5.5\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 3 items\n",
      "\n",
      "t_2cd27d8b688c4eb9be5163904688617e.py::test_database_exists \u001b[32mPASSED\u001b[0m\u001b[32m                           [ 33%]\u001b[0m\n",
      "t_2cd27d8b688c4eb9be5163904688617e.py::test_database_name_exact_match \u001b[32mPASSED\u001b[0m\u001b[32m                 [ 66%]\u001b[0m\n",
      "t_2cd27d8b688c4eb9be5163904688617e.py::test_database_is_accessible \u001b[32mPASSED\u001b[0m\u001b[32m                    [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m======================================== \u001b[32m\u001b[1m3 passed\u001b[0m\u001b[32m in 0.25s\u001b[0m\u001b[32m ========================================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%ipytest -vv\n",
    "\n",
    "def test_database_exists(postgres_cursor):\n",
    "    \"\"\"Verify sql_retail_analytics_warehouse database exists.\"\"\"\n",
    "    postgres_cursor.execute(\"\"\"\n",
    "        SELECT COUNT(*)\n",
    "        FROM pg_database\n",
    "        WHERE datname = %s\n",
    "    \"\"\", (TARGET_DB,))\n",
    "    \n",
    "    count = postgres_cursor.fetchone()[0]\n",
    "    assert count == 1, f\"Database '{TARGET_DB}' must exist\"\n",
    "\n",
    "def test_database_name_exact_match(postgres_cursor):\n",
    "    \"\"\"Verify database name matches exactly (case-sensitive).\"\"\"\n",
    "    postgres_cursor.execute(\"\"\"\n",
    "        SELECT datname\n",
    "        FROM pg_database\n",
    "        WHERE datname = %s\n",
    "    \"\"\", (TARGET_DB,))\n",
    "    \n",
    "    result = postgres_cursor.fetchone()\n",
    "    assert result is not None, f\"Database '{TARGET_DB}' not found\"\n",
    "    assert result[0] == TARGET_DB, f\"Database name mismatch: expected '{TARGET_DB}', got '{result[0]}'\"\n",
    "\n",
    "def test_database_is_accessible(target_cursor):\n",
    "    \"\"\"Verify we can connect to and query the database.\"\"\"\n",
    "    target_cursor.execute(\"SELECT current_database()\")\n",
    "    current_db = target_cursor.fetchone()[0]\n",
    "    assert current_db == TARGET_DB, f\"Connected to wrong database: {current_db}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4add5fdc",
   "metadata": {},
   "source": [
    "## Test Suite 2: Encoding Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5433ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m======================================= test session starts =======================================\u001b[0m\n",
      "platform win32 -- Python 3.12.4, pytest-8.4.2, pluggy-1.6.0 -- c:\\Users\\Laurent\\Studies\\sql-ultimate-course\\Udemy-SQL-Data-Warehouse-Project\\.venv\\Scripts\\python.exe\n",
      "cachedir: .pytest_cache\n",
      "rootdir: c:\\Users\\Laurent\\Studies\\sql-ultimate-course\\Udemy-SQL-Data-Warehouse-Project\\tests\\tests_setup\n",
      "plugins: anyio-4.11.0, nbmake-1.5.5\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 3 items\n",
      "\n",
      "t_2cd27d8b688c4eb9be5163904688617e.py::test_database_encoding_utf8 \u001b[32mPASSED\u001b[0m\u001b[32m                    [ 33%]\u001b[0m\n",
      "t_2cd27d8b688c4eb9be5163904688617e.py::test_database_encoding_from_connection \u001b[32mPASSED\u001b[0m\u001b[32m         [ 66%]\u001b[0m\n",
      "t_2cd27d8b688c4eb9be5163904688617e.py::test_client_encoding_utf8 \u001b[32mPASSED\u001b[0m\u001b[32m                      [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m======================================== \u001b[32m\u001b[1m3 passed\u001b[0m\u001b[32m in 0.26s\u001b[0m\u001b[32m ========================================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%ipytest -vv\n",
    "\n",
    "def test_database_encoding_utf8(postgres_cursor):\n",
    "    \"\"\"Verify database uses UTF8 encoding.\"\"\"\n",
    "    postgres_cursor.execute(\"\"\"\n",
    "        SELECT pg_encoding_to_char(encoding) AS encoding\n",
    "        FROM pg_database\n",
    "        WHERE datname = %s\n",
    "    \"\"\", (TARGET_DB,))\n",
    "    \n",
    "    encoding = postgres_cursor.fetchone()[0]\n",
    "    assert encoding == 'UTF8', f\"Expected UTF8 encoding, got '{encoding}'\"\n",
    "\n",
    "def test_database_encoding_from_connection(target_cursor):\n",
    "    \"\"\"Verify encoding setting from within the database.\"\"\"\n",
    "    target_cursor.execute(\"SHOW server_encoding\")\n",
    "    encoding = target_cursor.fetchone()[0]\n",
    "    assert encoding == 'UTF8', f\"Server encoding should be UTF8, got '{encoding}'\"\n",
    "\n",
    "def test_client_encoding_utf8(target_cursor):\n",
    "    \"\"\"Verify client encoding is also UTF8.\"\"\"\n",
    "    target_cursor.execute(\"SHOW client_encoding\")\n",
    "    encoding = target_cursor.fetchone()[0]\n",
    "    assert encoding == 'UTF8', f\"Client encoding should be UTF8, got '{encoding}'\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97599af8",
   "metadata": {},
   "source": [
    "## Test Suite 3: Locale Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f34b54c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m======================================= test session starts =======================================\u001b[0m\n",
      "platform win32 -- Python 3.12.4, pytest-8.4.2, pluggy-1.6.0 -- c:\\Users\\Laurent\\Studies\\sql-ultimate-course\\Udemy-SQL-Data-Warehouse-Project\\.venv\\Scripts\\python.exe\n",
      "cachedir: .pytest_cache\n",
      "rootdir: c:\\Users\\Laurent\\Studies\\sql-ultimate-course\\Udemy-SQL-Data-Warehouse-Project\\tests\\tests_setup\n",
      "plugins: anyio-4.11.0, nbmake-1.5.5\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 4 items\n",
      "\n",
      "t_2cd27d8b688c4eb9be5163904688617e.py::test_database_collation_en_gb collected 4 items\n",
      "\n",
      "t_2cd27d8b688c4eb9be5163904688617e.py::test_database_collation_en_gb \u001b[32mPASSED\u001b[0m\u001b[32m                  [ 25%]\u001b[0m\n",
      "t_2cd27d8b688c4eb9be5163904688617e.py::test_database_ctype_en_gb \u001b[32mPASSED\u001b[0m\u001b[32m                      [ 50%]\u001b[0m\n",
      "t_2cd27d8b688c4eb9be5163904688617e.py::test_lc_collate_matches_database_setting \u001b[32mPASSED\u001b[0m\u001b[32m                  [ 25%]\u001b[0m\n",
      "t_2cd27d8b688c4eb9be5163904688617e.py::test_database_ctype_en_gb \u001b[32mPASSED\u001b[0m\u001b[32m                      [ 50%]\u001b[0m\n",
      "t_2cd27d8b688c4eb9be5163904688617e.py::test_lc_collate_matches_database_setting \u001b[32mPASSED\u001b[0m\u001b[32m       [ 75%]\u001b[0m\n",
      "t_2cd27d8b688c4eb9be5163904688617e.py::test_lc_ctype_matches_database_setting \u001b[32mPASSED\u001b[0m\u001b[32m         [100%]\u001b[0m\u001b[32mPASSED\u001b[0m\u001b[32m       [ 75%]\u001b[0m\n",
      "t_2cd27d8b688c4eb9be5163904688617e.py::test_lc_ctype_matches_database_setting \u001b[32mPASSED\u001b[0m\u001b[32m         [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m======================================== \u001b[32m\u001b[1m4 passed\u001b[0m\u001b[32m in 0.22s\u001b[0m\u001b[32m ========================================\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[32m======================================== \u001b[32m\u001b[1m4 passed\u001b[0m\u001b[32m in 0.22s\u001b[0m\u001b[32m ========================================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%ipytest -vv\n",
    "\n",
    "def test_database_collation_en_gb(postgres_cursor):\n",
    "    \"\"\"Verify database uses en_GB.UTF-8 collation.\"\"\"\n",
    "    postgres_cursor.execute(\"\"\"\n",
    "        SELECT datcollate\n",
    "        FROM pg_database\n",
    "        WHERE datname = %s\n",
    "    \"\"\", (TARGET_DB,))\n",
    "    \n",
    "    collation = postgres_cursor.fetchone()[0]\n",
    "    assert collation == 'en_GB.UTF-8', f\"Expected 'en_GB.UTF-8' collation, got '{collation}'\"\n",
    "\n",
    "def test_database_ctype_en_gb(postgres_cursor):\n",
    "    \"\"\"Verify database uses en_GB.UTF-8 character classification.\"\"\"\n",
    "    postgres_cursor.execute(\"\"\"\n",
    "        SELECT datctype\n",
    "        FROM pg_database\n",
    "        WHERE datname = %s\n",
    "    \"\"\", (TARGET_DB,))\n",
    "    \n",
    "    ctype = postgres_cursor.fetchone()[0]\n",
    "    assert ctype == 'en_GB.UTF-8', f\"Expected 'en_GB.UTF-8' ctype, got '{ctype}'\"\n",
    "\n",
    "def test_lc_collate_matches_database_setting(postgres_cursor, target_cursor):\n",
    "    \"\"\"Verify LC_COLLATE visible in current session matches database configuration.\"\"\"\n",
    "    # Get database collation from catalog\n",
    "    postgres_cursor.execute(\"\"\"\n",
    "        SELECT datcollate\n",
    "        FROM pg_database\n",
    "        WHERE datname = %s\n",
    "    \"\"\", (TARGET_DB,))\n",
    "    expected_collate = postgres_cursor.fetchone()[0]\n",
    "    \n",
    "    # Query via pg_settings or database properties\n",
    "    target_cursor.execute(\"\"\"\n",
    "        SELECT datcollate\n",
    "        FROM pg_database\n",
    "        WHERE datname = current_database()\n",
    "    \"\"\")\n",
    "    actual_collate = target_cursor.fetchone()[0]\n",
    "    \n",
    "    assert actual_collate == expected_collate, \\\n",
    "        f\"LC_COLLATE mismatch: expected '{expected_collate}', got '{actual_collate}'\"\n",
    "\n",
    "def test_lc_ctype_matches_database_setting(postgres_cursor, target_cursor):\n",
    "    \"\"\"Verify LC_CTYPE visible in current session matches database configuration.\"\"\"\n",
    "    # Get database ctype from catalog\n",
    "    postgres_cursor.execute(\"\"\"\n",
    "        SELECT datctype\n",
    "        FROM pg_database\n",
    "        WHERE datname = %s\n",
    "    \"\"\", (TARGET_DB,))\n",
    "    expected_ctype = postgres_cursor.fetchone()[0]\n",
    "    \n",
    "    # Query via database properties\n",
    "    target_cursor.execute(\"\"\"\n",
    "        SELECT datctype\n",
    "        FROM pg_database\n",
    "        WHERE datname = current_database()\n",
    "    \"\"\")\n",
    "    actual_ctype = target_cursor.fetchone()[0]\n",
    "    \n",
    "    assert actual_ctype == expected_ctype, \\\n",
    "        f\"LC_CTYPE mismatch: expected '{expected_ctype}', got '{actual_ctype}'\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e06783f",
   "metadata": {},
   "source": [
    "## Test Suite 4: Template Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80f626a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m======================================= test session starts =======================================\u001b[0m\n",
      "platform win32 -- Python 3.12.4, pytest-8.4.2, pluggy-1.6.0 -- c:\\Users\\Laurent\\Studies\\sql-ultimate-course\\Udemy-SQL-Data-Warehouse-Project\\.venv\\Scripts\\python.exe\n",
      "cachedir: .pytest_cache\n",
      "rootdir: c:\\Users\\Laurent\\Studies\\sql-ultimate-course\\Udemy-SQL-Data-Warehouse-Project\\tests\\tests_setup\n",
      "plugins: anyio-4.11.0, nbmake-1.5.5\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 3 items\n",
      "\n",
      "t_2cd27d8b688c4eb9be5163904688617e.py::test_database_allows_connections collected 3 items\n",
      "\n",
      "t_2cd27d8b688c4eb9be5163904688617e.py::test_database_allows_connections \u001b[32mPASSED\u001b[0m\u001b[32m               [ 33%]\u001b[0m\n",
      "t_2cd27d8b688c4eb9be5163904688617e.py::test_database_not_a_template \u001b[32mPASSED\u001b[0m\u001b[32m                   [ 66%]\u001b[0m\n",
      "t_2cd27d8b688c4eb9be5163904688617e.py::test_no_active_connections_limit \u001b[32mPASSED\u001b[0m\u001b[32m               [100%]\u001b[0m\u001b[32mPASSED\u001b[0m\u001b[32m               [ 33%]\u001b[0m\n",
      "t_2cd27d8b688c4eb9be5163904688617e.py::test_database_not_a_template \u001b[32mPASSED\u001b[0m\u001b[32m                   [ 66%]\u001b[0m\n",
      "t_2cd27d8b688c4eb9be5163904688617e.py::test_no_active_connections_limit \u001b[32mPASSED\u001b[0m\u001b[32m               [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m======================================== \u001b[32m\u001b[1m3 passed\u001b[0m\u001b[32m in 0.11s\u001b[0m\u001b[32m ========================================\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[32m======================================== \u001b[32m\u001b[1m3 passed\u001b[0m\u001b[32m in 0.11s\u001b[0m\u001b[32m ========================================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%ipytest -vv\n",
    "\n",
    "def test_database_allows_connections(postgres_cursor):\n",
    "    \"\"\"Verify database allows connections (not a template).\"\"\"\n",
    "    postgres_cursor.execute(\"\"\"\n",
    "        SELECT datallowconn\n",
    "        FROM pg_database\n",
    "        WHERE datname = %s\n",
    "    \"\"\", (TARGET_DB,))\n",
    "    \n",
    "    allows_conn = postgres_cursor.fetchone()[0]\n",
    "    assert allows_conn is True, \"Database should allow connections\"\n",
    "\n",
    "def test_database_not_a_template(postgres_cursor):\n",
    "    \"\"\"Verify database is not marked as a template.\"\"\"\n",
    "    postgres_cursor.execute(\"\"\"\n",
    "        SELECT datistemplate\n",
    "        FROM pg_database\n",
    "        WHERE datname = %s\n",
    "    \"\"\", (TARGET_DB,))\n",
    "    \n",
    "    is_template = postgres_cursor.fetchone()[0]\n",
    "    assert is_template is False, \"Database should not be a template\"\n",
    "\n",
    "def test_no_active_connections_limit(postgres_cursor):\n",
    "    \"\"\"Verify database has no connection limit (-1 = unlimited).\"\"\"\n",
    "    postgres_cursor.execute(\"\"\"\n",
    "        SELECT datconnlimit\n",
    "        FROM pg_database\n",
    "        WHERE datname = %s\n",
    "    \"\"\", (TARGET_DB,))\n",
    "    \n",
    "    conn_limit = postgres_cursor.fetchone()[0]\n",
    "    assert conn_limit == -1, f\"Expected unlimited connections (-1), got {conn_limit}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de06c8e",
   "metadata": {},
   "source": [
    "## Test Suite 5: Ownership and Privileges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42995fb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m======================================= test session starts =======================================\u001b[0m\n",
      "platform win32 -- Python 3.12.4, pytest-8.4.2, pluggy-1.6.0 -- c:\\Users\\Laurent\\Studies\\sql-ultimate-course\\Udemy-SQL-Data-Warehouse-Project\\.venv\\Scripts\\python.exe\n",
      "cachedir: .pytest_cache\n",
      "rootdir: c:\\Users\\Laurent\\Studies\\sql-ultimate-course\\Udemy-SQL-Data-Warehouse-Project\\tests\\tests_setup\n",
      "plugins: anyio-4.11.0, nbmake-1.5.5\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 2 items\n",
      "\n",
      "t_2cd27d8b688c4eb9be5163904688617e.py::test_database_owner collected 2 items\n",
      "\n",
      "t_2cd27d8b688c4eb9be5163904688617e.py::test_database_owner \u001b[32mPASSED\u001b[0m\u001b[32m                            [ 50%]\u001b[0m\n",
      "t_2cd27d8b688c4eb9be5163904688617e.py::test_current_user_can_create_schema \u001b[32mPASSED\u001b[0m\u001b[32m                            [ 50%]\u001b[0m\n",
      "t_2cd27d8b688c4eb9be5163904688617e.py::test_current_user_can_create_schema \u001b[32mPASSED\u001b[0m\u001b[32m            [100%]\u001b[0m\u001b[32mPASSED\u001b[0m\u001b[32m            [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m======================================== \u001b[32m\u001b[1m2 passed\u001b[0m\u001b[32m in 0.24s\u001b[0m\u001b[32m ========================================\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[32m======================================== \u001b[32m\u001b[1m2 passed\u001b[0m\u001b[32m in 0.24s\u001b[0m\u001b[32m ========================================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%ipytest -vv\n",
    "\n",
    "def test_database_owner(postgres_cursor):\n",
    "    \"\"\"Verify database is owned by postgres user.\"\"\"\n",
    "    postgres_cursor.execute(\"\"\"\n",
    "        SELECT pg_catalog.pg_get_userbyid(d.datdba) AS owner\n",
    "        FROM pg_catalog.pg_database d\n",
    "        WHERE d.datname = %s\n",
    "    \"\"\", (TARGET_DB,))\n",
    "    \n",
    "    owner = postgres_cursor.fetchone()[0]\n",
    "    # Owner should be postgres or the creating user\n",
    "    assert owner is not None, \"Database must have an owner\"\n",
    "    assert len(owner) > 0, \"Owner name should not be empty\"\n",
    "\n",
    "def test_current_user_can_create_schema(target_cursor):\n",
    "    \"\"\"Verify current user has privileges to create schemas.\"\"\"\n",
    "    # Try to create a test schema (will rollback)\n",
    "    target_cursor.execute(\"\"\"\n",
    "        CREATE SCHEMA IF NOT EXISTS test_privilege_check\n",
    "    \"\"\")\n",
    "    \n",
    "    # Verify it was created\n",
    "    target_cursor.execute(\"\"\"\n",
    "        SELECT COUNT(*)\n",
    "        FROM information_schema.schemata\n",
    "        WHERE schema_name = 'test_privilege_check'\n",
    "    \"\"\")\n",
    "    \n",
    "    count = target_cursor.fetchone()[0]\n",
    "    assert count == 1, \"User should be able to create schemas\"\n",
    "    \n",
    "    # Clean up\n",
    "    target_cursor.execute(\"DROP SCHEMA IF EXISTS test_privilege_check CASCADE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189b8675",
   "metadata": {},
   "source": [
    "## Test Suite 6: Clean State Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02a46118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m======================================= test session starts =======================================\u001b[0m\n",
      "platform win32 -- Python 3.12.4, pytest-8.4.2, pluggy-1.6.0 -- c:\\Users\\Laurent\\Studies\\sql-ultimate-course\\Udemy-SQL-Data-Warehouse-Project\\.venv\\Scripts\\python.exe\n",
      "cachedir: .pytest_cache\n",
      "rootdir: c:\\Users\\Laurent\\Studies\\sql-ultimate-course\\Udemy-SQL-Data-Warehouse-Project\\tests\\tests_setup\n",
      "plugins: anyio-4.11.0, nbmake-1.5.5\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 2 items\n",
      "\n",
      "t_2cd27d8b688c4eb9be5163904688617e.py::test_expected_default_schemas_only collected 2 items\n",
      "\n",
      "t_2cd27d8b688c4eb9be5163904688617e.py::test_expected_default_schemas_only \u001b[32mPASSED\u001b[0m\u001b[32m             [ 50%]\u001b[0m\n",
      "t_2cd27d8b688c4eb9be5163904688617e.py::test_database_size_reasonable \u001b[32mPASSED\u001b[0m\u001b[32m             [ 50%]\u001b[0m\n",
      "t_2cd27d8b688c4eb9be5163904688617e.py::test_database_size_reasonable \u001b[32mPASSED\u001b[0m\u001b[32m                  [100%]\u001b[0m\u001b[32mPASSED\u001b[0m\u001b[32m                  [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m======================================== \u001b[32m\u001b[1m2 passed\u001b[0m\u001b[32m in 0.44s\u001b[0m\u001b[32m ========================================\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[32m======================================== \u001b[32m\u001b[1m2 passed\u001b[0m\u001b[32m in 0.44s\u001b[0m\u001b[32m ========================================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%ipytest -vv\n",
    "\n",
    "def test_expected_default_schemas_only(target_cursor):\n",
    "    \"\"\"Verify only default PostgreSQL schemas exist (if using template0).\"\"\"\n",
    "    target_cursor.execute(\"\"\"\n",
    "        SELECT schema_name\n",
    "        FROM information_schema.schemata\n",
    "        WHERE schema_name NOT IN ('pg_catalog', 'information_schema', 'pg_toast')\n",
    "        ORDER BY schema_name\n",
    "    \"\"\")\n",
    "    \n",
    "    schemas = [row[0] for row in target_cursor.fetchall()]\n",
    "    \n",
    "    # Should only have 'public' by default (if clean template0)\n",
    "    # May have bronze/silver/gold if create_schemas.sql was run\n",
    "    # This test verifies no unexpected schemas exist\n",
    "    expected_schemas = {'public', 'bronze', 'silver', 'gold', 'setup'}\n",
    "    unexpected = set(schemas) - expected_schemas\n",
    "    \n",
    "    if unexpected:\n",
    "        print(f\"⚠️  Unexpected schemas found: {unexpected}\")\n",
    "        print(f\"   All schemas: {schemas}\")\n",
    "    \n",
    "    # At minimum, 'public' should exist\n",
    "    assert 'public' in schemas, \"Default 'public' schema should exist\"\n",
    "\n",
    "def test_database_size_reasonable(target_cursor):\n",
    "    \"\"\"Verify database size is reasonable for a clean database.\"\"\"\n",
    "    target_cursor.execute(\"\"\"\n",
    "        SELECT pg_size_pretty(pg_database_size(current_database())) AS size,\n",
    "               pg_database_size(current_database()) AS size_bytes\n",
    "    \"\"\")\n",
    "    \n",
    "    size_pretty, size_bytes = target_cursor.fetchone()\n",
    "    \n",
    "    # Clean database should be under 20MB\n",
    "    max_size_bytes = 20 * 1024 * 1024  # 20MB\n",
    "    \n",
    "    print(f\"Database size: {size_pretty}\")\n",
    "    assert size_bytes < max_size_bytes, \\\n",
    "        f\"Database seems too large for a clean database: {size_pretty}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae8ec37",
   "metadata": {},
   "source": [
    "## Test Suite 7: Connection and Session Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1fd0f95c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m======================================= test session starts =======================================\u001b[0m\n",
      "platform win32 -- Python 3.12.4, pytest-8.4.2, pluggy-1.6.0 -- c:\\Users\\Laurent\\Studies\\sql-ultimate-course\\Udemy-SQL-Data-Warehouse-Project\\.venv\\Scripts\\python.exe\n",
      "cachedir: .pytest_cache\n",
      "rootdir: c:\\Users\\Laurent\\Studies\\sql-ultimate-course\\Udemy-SQL-Data-Warehouse-Project\\tests\\tests_setup\n",
      "plugins: anyio-4.11.0, nbmake-1.5.5\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 4 items\n",
      "\n",
      "t_2cd27d8b688c4eb9be5163904688617e.py::test_timezone_setting collected 4 items\n",
      "\n",
      "t_2cd27d8b688c4eb9be5163904688617e.py::test_timezone_setting \u001b[32mPASSED\u001b[0m\u001b[32m                          [ 25%]\u001b[0m\n",
      "t_2cd27d8b688c4eb9be5163904688617e.py::test_datestyle_setting \u001b[32mPASSED\u001b[0m\u001b[32m                         [ 50%]\u001b[0m\n",
      "t_2cd27d8b688c4eb9be5163904688617e.py::test_can_create_table \u001b[32mPASSED\u001b[0m\u001b[32m                          [ 25%]\u001b[0m\n",
      "t_2cd27d8b688c4eb9be5163904688617e.py::test_datestyle_setting \u001b[32mPASSED\u001b[0m\u001b[32m                         [ 50%]\u001b[0m\n",
      "t_2cd27d8b688c4eb9be5163904688617e.py::test_can_create_table \u001b[32mPASSED\u001b[0m\u001b[32m                          [ 75%]\u001b[0m\n",
      "t_2cd27d8b688c4eb9be5163904688617e.py::test_can_insert_and_query_utf8_data \u001b[32mPASSED\u001b[0m\u001b[32m                          [ 75%]\u001b[0m\n",
      "t_2cd27d8b688c4eb9be5163904688617e.py::test_can_insert_and_query_utf8_data \u001b[32mPASSED\u001b[0m\u001b[32m            [100%]\u001b[0m\u001b[32mPASSED\u001b[0m\u001b[32m            [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m======================================== \u001b[32m\u001b[1m4 passed\u001b[0m\u001b[32m in 0.24s\u001b[0m\u001b[32m ========================================\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[32m======================================== \u001b[32m\u001b[1m4 passed\u001b[0m\u001b[32m in 0.24s\u001b[0m\u001b[32m ========================================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%ipytest -vv\n",
    "\n",
    "def test_timezone_setting(target_cursor):\n",
    "    \"\"\"Verify timezone is set (should have default or configured value).\"\"\"\n",
    "    target_cursor.execute(\"SHOW timezone\")\n",
    "    timezone = target_cursor.fetchone()[0]\n",
    "    assert timezone is not None, \"Timezone should be set\"\n",
    "    assert len(timezone) > 0, \"Timezone value should not be empty\"\n",
    "\n",
    "def test_datestyle_setting(target_cursor):\n",
    "    \"\"\"Verify DateStyle is set to ISO standard.\"\"\"\n",
    "    target_cursor.execute(\"SHOW datestyle\")\n",
    "    datestyle = target_cursor.fetchone()[0]\n",
    "    # Should contain 'ISO' for consistent date formatting\n",
    "    assert 'ISO' in datestyle, f\"DateStyle should include ISO, got '{datestyle}'\"\n",
    "\n",
    "def test_can_create_table(target_cursor):\n",
    "    \"\"\"Verify basic DDL operations work.\"\"\"\n",
    "    # Create a test table\n",
    "    target_cursor.execute(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS test_table_creation (\n",
    "            id SERIAL PRIMARY KEY,\n",
    "            name TEXT NOT NULL\n",
    "        )\n",
    "    \"\"\")\n",
    "    \n",
    "    # Verify it exists\n",
    "    target_cursor.execute(\"\"\"\n",
    "        SELECT COUNT(*)\n",
    "        FROM information_schema.tables\n",
    "        WHERE table_name = 'test_table_creation'\n",
    "    \"\"\")\n",
    "    \n",
    "    count = target_cursor.fetchone()[0]\n",
    "    assert count == 1, \"Should be able to create tables\"\n",
    "    \n",
    "    # Clean up\n",
    "    target_cursor.execute(\"DROP TABLE IF EXISTS test_table_creation\")\n",
    "\n",
    "def test_can_insert_and_query_utf8_data(target_cursor):\n",
    "    \"\"\"Verify UTF-8 data can be inserted and queried correctly.\"\"\"\n",
    "    # Create temp table\n",
    "    target_cursor.execute(\"\"\"\n",
    "        CREATE TEMP TABLE test_utf8 (data TEXT)\n",
    "    \"\"\")\n",
    "    \n",
    "    # Insert various UTF-8 characters\n",
    "    test_strings = [\n",
    "        'Hello World',\n",
    "        'Café',\n",
    "        '日本語',  # Japanese\n",
    "        '🎯📊',    # Emojis\n",
    "        'Ελληνικά'  # Greek\n",
    "    ]\n",
    "    \n",
    "    for test_str in test_strings:\n",
    "        target_cursor.execute(\n",
    "            \"INSERT INTO test_utf8 (data) VALUES (%s)\",\n",
    "            (test_str,)\n",
    "        )\n",
    "    \n",
    "    # Query back and verify\n",
    "    target_cursor.execute(\"SELECT data FROM test_utf8 ORDER BY data\")\n",
    "    results = [row[0] for row in target_cursor.fetchall()]\n",
    "    \n",
    "    # All strings should be retrievable\n",
    "    assert len(results) == len(test_strings), \"All UTF-8 strings should be retrievable\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c419b624",
   "metadata": {},
   "source": [
    "## Summary: Run All Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8caf6494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run all tests in this notebook\n",
    "ipytest.run('-vv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d6d313",
   "metadata": {},
   "source": [
    "## Manual Inspection: Database Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5dc4c8a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🗄️  Database Configuration:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Laurent\\AppData\\Local\\Temp\\ipykernel_6856\\2333232674.py:5: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_db_info = pd.read_sql(f\"\"\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "0",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "cc8c250b-4898-4a9e-90ff-d108fd760e3d",
       "rows": [
        [
         "database_name",
         "sql_retail_analytics_warehouse"
        ],
        [
         "owner",
         "postgres"
        ],
        [
         "encoding",
         "UTF8"
        ],
        [
         "collation",
         "en_GB.UTF-8"
        ],
        [
         "ctype",
         "en_GB.UTF-8"
        ],
        [
         "allows_connections",
         "True"
        ],
        [
         "connection_limit",
         "-1"
        ],
        [
         "is_template",
         "False"
        ],
        [
         "size",
         "8062 kB"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 9
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>database_name</th>\n",
       "      <td>sql_retail_analytics_warehouse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>owner</th>\n",
       "      <td>postgres</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>encoding</th>\n",
       "      <td>UTF8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>collation</th>\n",
       "      <td>en_GB.UTF-8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ctype</th>\n",
       "      <td>en_GB.UTF-8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>allows_connections</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>connection_limit</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_template</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>size</th>\n",
       "      <td>8062 kB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 0\n",
       "database_name       sql_retail_analytics_warehouse\n",
       "owner                                     postgres\n",
       "encoding                                      UTF8\n",
       "collation                              en_GB.UTF-8\n",
       "ctype                                  en_GB.UTF-8\n",
       "allows_connections                            True\n",
       "connection_limit                                -1\n",
       "is_template                                  False\n",
       "size                                       8062 kB"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⚙️  Session Settings:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Laurent\\AppData\\Local\\Temp\\ipykernel_6856\\2333232674.py:29: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_settings = pd.read_sql(\"\"\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "setting",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "value",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "67187289-1643-4840-8240-dd9e2b659613",
       "rows": [
        [
         "0",
         "client_encoding",
         "UTF8"
        ],
        [
         "1",
         "datestyle",
         "ISO, DMY"
        ],
        [
         "2",
         "server_encoding",
         "UTF8"
        ],
        [
         "3",
         "timezone",
         "Europe/London"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 4
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>setting</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>client_encoding</td>\n",
       "      <td>UTF8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>datestyle</td>\n",
       "      <td>ISO, DMY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>server_encoding</td>\n",
       "      <td>UTF8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>timezone</td>\n",
       "      <td>Europe/London</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           setting          value\n",
       "0  client_encoding           UTF8\n",
       "1        datestyle       ISO, DMY\n",
       "2  server_encoding           UTF8\n",
       "3         timezone  Europe/London"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🌍 Locale Settings (from database catalog):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Laurent\\AppData\\Local\\Temp\\ipykernel_6856\\2333232674.py:46: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_locale = pd.read_sql(f\"\"\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "setting",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "value",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "0b1e314d-1999-494d-85c9-d8002762a901",
       "rows": [
        [
         "0",
         "lc_collate",
         "en_GB.UTF-8"
        ],
        [
         "1",
         "lc_ctype",
         "en_GB.UTF-8"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 2
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>setting</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lc_collate</td>\n",
       "      <td>en_GB.UTF-8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lc_ctype</td>\n",
       "      <td>en_GB.UTF-8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      setting        value\n",
       "0  lc_collate  en_GB.UTF-8\n",
       "1    lc_ctype  en_GB.UTF-8"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📁 Schemas:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Laurent\\AppData\\Local\\Temp\\ipykernel_6856\\2333232674.py:65: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_schemas = pd.read_sql(\"\"\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "schema_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "owner",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "638ed19e-575a-4148-a655-7bef6b15e25f",
       "rows": [
        [
         "0",
         "bronze",
         "postgres"
        ],
        [
         "1",
         "gold",
         "postgres"
        ],
        [
         "2",
         "pg_temp_28",
         "postgres"
        ],
        [
         "3",
         "pg_toast_temp_28",
         "postgres"
        ],
        [
         "4",
         "public",
         "pg_database_owner"
        ],
        [
         "5",
         "silver",
         "postgres"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 6
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>schema_name</th>\n",
       "      <th>owner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bronze</td>\n",
       "      <td>postgres</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gold</td>\n",
       "      <td>postgres</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pg_temp_28</td>\n",
       "      <td>postgres</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pg_toast_temp_28</td>\n",
       "      <td>postgres</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>public</td>\n",
       "      <td>pg_database_owner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>silver</td>\n",
       "      <td>postgres</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        schema_name              owner\n",
       "0            bronze           postgres\n",
       "1              gold           postgres\n",
       "2        pg_temp_28           postgres\n",
       "3  pg_toast_temp_28           postgres\n",
       "4            public  pg_database_owner\n",
       "5            silver           postgres"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Database Statistics:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Laurent\\AppData\\Local\\Temp\\ipykernel_6856\\2333232674.py:78: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_stats = pd.read_sql(\"\"\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "database",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "total_size",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "user_tables",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "user_schemas",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "a774ebd5-6405-4d91-85de-94bcddef5b05",
       "rows": [
        [
         "0",
         "sql_retail_analytics_warehouse",
         "8062 kB",
         "0",
         "6"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 1
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>database</th>\n",
       "      <th>total_size</th>\n",
       "      <th>user_tables</th>\n",
       "      <th>user_schemas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sql_retail_analytics_warehouse</td>\n",
       "      <td>8062 kB</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         database total_size  user_tables  user_schemas\n",
       "0  sql_retail_analytics_warehouse    8062 kB            0             6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Inspection complete\n"
     ]
    }
   ],
   "source": [
    "# Connect to postgres database to query catalog\n",
    "conn_postgres = psycopg2.connect(database='postgres', **DB_CONFIG)\n",
    "\n",
    "# Get comprehensive database information\n",
    "df_db_info = pd.read_sql(f\"\"\"\n",
    "    SELECT\n",
    "        d.datname                                  AS database_name,\n",
    "        pg_catalog.pg_get_userbyid(d.datdba)       AS owner,\n",
    "        pg_catalog.pg_encoding_to_char(d.encoding) AS encoding,\n",
    "        d.datcollate                               AS collation,\n",
    "        d.datctype                                 AS ctype,\n",
    "        d.datallowconn                             AS allows_connections,\n",
    "        d.datconnlimit                             AS connection_limit,\n",
    "        d.datistemplate                            AS is_template,\n",
    "        pg_size_pretty(pg_database_size(d.datname)) AS size\n",
    "    FROM pg_catalog.pg_database d\n",
    "    WHERE d.datname = '{TARGET_DB}'\n",
    "\"\"\", conn_postgres)\n",
    "\n",
    "print(\"\\n🗄️  Database Configuration:\")\n",
    "display(df_db_info.T)  # Transpose for better readability\n",
    "\n",
    "conn_postgres.close()\n",
    "\n",
    "# Connect to target database for additional info\n",
    "conn_target = psycopg2.connect(database=TARGET_DB, **DB_CONFIG)\n",
    "\n",
    "# Get session settings (excluding lc_collate and lc_ctype which are not runtime parameters)\n",
    "df_settings = pd.read_sql(\"\"\"\n",
    "    SELECT\n",
    "        'server_encoding' AS setting,\n",
    "        current_setting('server_encoding') AS value\n",
    "    UNION ALL\n",
    "    SELECT 'client_encoding', current_setting('client_encoding')\n",
    "    UNION ALL\n",
    "    SELECT 'timezone', current_setting('timezone')\n",
    "    UNION ALL\n",
    "    SELECT 'datestyle', current_setting('datestyle')\n",
    "    ORDER BY setting\n",
    "\"\"\", conn_target)\n",
    "\n",
    "print(\"\\n⚙️  Session Settings:\")\n",
    "display(df_settings)\n",
    "\n",
    "# Get locale settings from database catalog (not runtime parameters)\n",
    "df_locale = pd.read_sql(f\"\"\"\n",
    "    SELECT\n",
    "        'lc_collate' AS setting,\n",
    "        datcollate AS value\n",
    "    FROM pg_database\n",
    "    WHERE datname = '{TARGET_DB}'\n",
    "    UNION ALL\n",
    "    SELECT\n",
    "        'lc_ctype' AS setting,\n",
    "        datctype AS value\n",
    "    FROM pg_database\n",
    "    WHERE datname = '{TARGET_DB}'\n",
    "    ORDER BY setting\n",
    "\"\"\", conn_target)\n",
    "\n",
    "print(\"\\n🌍 Locale Settings (from database catalog):\")\n",
    "display(df_locale)\n",
    "\n",
    "# Get list of schemas\n",
    "df_schemas = pd.read_sql(\"\"\"\n",
    "    SELECT\n",
    "        schema_name,\n",
    "        pg_catalog.pg_get_userbyid(schema_owner::regrole::oid) AS owner\n",
    "    FROM information_schema.schemata\n",
    "    WHERE schema_name NOT IN ('pg_catalog', 'information_schema', 'pg_toast')\n",
    "    ORDER BY schema_name\n",
    "\"\"\", conn_target)\n",
    "\n",
    "print(\"\\n📁 Schemas:\")\n",
    "display(df_schemas)\n",
    "\n",
    "# Get database statistics\n",
    "df_stats = pd.read_sql(\"\"\"\n",
    "    SELECT\n",
    "        current_database() AS database,\n",
    "        pg_size_pretty(pg_database_size(current_database())) AS total_size,\n",
    "        (\n",
    "            SELECT COUNT(*)\n",
    "            FROM information_schema.tables\n",
    "            WHERE table_schema NOT IN ('pg_catalog', 'information_schema')\n",
    "        ) AS user_tables,\n",
    "        (\n",
    "            SELECT COUNT(*)\n",
    "            FROM information_schema.schemata\n",
    "            WHERE schema_name NOT IN ('pg_catalog', 'information_schema', 'pg_toast')\n",
    "        ) AS user_schemas\n",
    "\"\"\", conn_target)\n",
    "\n",
    "print(\"\\n📊 Database Statistics:\")\n",
    "display(df_stats)\n",
    "\n",
    "conn_target.close()\n",
    "print(\"\\n✅ Inspection complete\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

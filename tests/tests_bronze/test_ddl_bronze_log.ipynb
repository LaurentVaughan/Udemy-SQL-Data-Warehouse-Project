{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c26ed62d",
   "metadata": {},
   "source": [
    "# Test Suite: bronze.load_log DDL Validation\n",
    "\n",
    "**Purpose:** Validate the structure and configuration of `bronze.load_log` table\n",
    "\n",
    "**Scope:**\n",
    "- Table existence and schema placement\n",
    "- Column definitions (names, types, nullability)\n",
    "- Index creation and naming\n",
    "- Constraint definitions\n",
    "- Extension requirements (pgcrypto)\n",
    "\n",
    "**Usage:**\n",
    "```bash\n",
    "# Run all tests\n",
    "pytest tests/tests_bronze/test_ddl_bronze_log.ipynb --nbmake\n",
    "\n",
    "# Or run interactively in this notebook\n",
    "```\n",
    "\n",
    "**Prerequisites:**\n",
    "- Database connection configured\n",
    "- `scripts/bronze/ddl_bronze_log.sql` has been executed\n",
    "- Required packages: psycopg2, pytest, ipytest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf50e77",
   "metadata": {},
   "source": [
    "## Setup: Import Dependencies & Configure Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46dfbf92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import psycopg2\n",
    "from psycopg2 import sql\n",
    "import pytest\n",
    "import ipytest\n",
    "import pandas as pd\n",
    "\n",
    "# Configure ipytest for notebook usage\n",
    "ipytest.autoconfig()\n",
    "\n",
    "# Database connection parameters\n",
    "DB_CONFIG = {\n",
    "    'host': 'localhost',\n",
    "    'database': 'sql_retail_analytics_warehouse',\n",
    "    'user': 'postgres',\n",
    "    'password': os.getenv('POSTGRES_PASSWORD', 'your_password_here')\n",
    "}\n",
    "\n",
    "print(\"âœ… Dependencies imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfdb7e0",
   "metadata": {},
   "source": [
    "## Fixture: Database Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b888bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pytest.fixture(scope='module')\n",
    "def db_connection():\n",
    "    \"\"\"Create a database connection for tests.\"\"\"\n",
    "    conn = psycopg2.connect(**DB_CONFIG)\n",
    "    conn.autocommit = True\n",
    "    yield conn\n",
    "    conn.close()\n",
    "\n",
    "@pytest.fixture(scope='module')\n",
    "def db_cursor(db_connection):\n",
    "    \"\"\"Create a cursor for executing queries.\"\"\"\n",
    "    cursor = db_connection.cursor()\n",
    "    yield cursor\n",
    "    cursor.close()\n",
    "\n",
    "print(\"âœ… Fixtures defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083a1c3e",
   "metadata": {},
   "source": [
    "## Test 1: Extension and Schema Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2295cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ipytest -vv\n",
    "\n",
    "def test_pgcrypto_extension_exists(db_cursor):\n",
    "    \"\"\"Verify pgcrypto extension is installed (required for gen_random_uuid()).\"\"\"\n",
    "    db_cursor.execute(\"\"\"\n",
    "        SELECT COUNT(*) \n",
    "        FROM pg_extension \n",
    "        WHERE extname = 'pgcrypto'\n",
    "    \"\"\")\n",
    "    count = db_cursor.fetchone()[0]\n",
    "    assert count == 1, \"pgcrypto extension must be installed\"\n",
    "\n",
    "def test_bronze_schema_exists(db_cursor):\n",
    "    \"\"\"Verify bronze schema exists.\"\"\"\n",
    "    db_cursor.execute(\"\"\"\n",
    "        SELECT COUNT(*) \n",
    "        FROM information_schema.schemata \n",
    "        WHERE schema_name = 'bronze'\n",
    "    \"\"\")\n",
    "    count = db_cursor.fetchone()[0]\n",
    "    assert count == 1, \"bronze schema must exist\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23d6d3b",
   "metadata": {},
   "source": [
    "## Test 2: Table Existence and Basic Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738e1211",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ipytest -vv\n",
    "\n",
    "def test_load_log_table_exists(db_cursor):\n",
    "    \"\"\"Verify bronze.load_log table exists.\"\"\"\n",
    "    db_cursor.execute(\"\"\"\n",
    "        SELECT COUNT(*) \n",
    "        FROM information_schema.tables \n",
    "        WHERE table_schema = 'bronze' \n",
    "          AND table_name = 'load_log'\n",
    "    \"\"\")\n",
    "    count = db_cursor.fetchone()[0]\n",
    "    assert count == 1, \"bronze.load_log table must exist\"\n",
    "\n",
    "def test_load_log_column_count(db_cursor):\n",
    "    \"\"\"Verify bronze.load_log has expected number of columns.\"\"\"\n",
    "    db_cursor.execute(\"\"\"\n",
    "        SELECT COUNT(*) \n",
    "        FROM information_schema.columns \n",
    "        WHERE table_schema = 'bronze' \n",
    "          AND table_name = 'load_log'\n",
    "    \"\"\")\n",
    "    count = db_cursor.fetchone()[0]\n",
    "    assert count == 11, \"bronze.load_log should have 11 columns\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84bd8fdd",
   "metadata": {},
   "source": [
    "## Test 3: Column Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59335aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ipytest -vv\n",
    "\n",
    "def test_load_log_column_definitions(db_cursor):\n",
    "    \"\"\"Verify all required columns exist with correct data types.\"\"\"\n",
    "    db_cursor.execute(\"\"\"\n",
    "        SELECT \n",
    "            column_name,\n",
    "            data_type,\n",
    "            is_nullable\n",
    "        FROM information_schema.columns\n",
    "        WHERE table_schema = 'bronze'\n",
    "          AND table_name = 'load_log'\n",
    "        ORDER BY ordinal_position\n",
    "    \"\"\")\n",
    "    \n",
    "    columns = db_cursor.fetchall()\n",
    "    column_dict = {col[0]: {'type': col[1], 'nullable': col[2]} for col in columns}\n",
    "    \n",
    "    # Expected column definitions\n",
    "    expected_columns = {\n",
    "        'id': {'type': 'bigint', 'nullable': 'NO'},\n",
    "        'run_id': {'type': 'uuid', 'nullable': 'NO'},\n",
    "        'phase': {'type': 'text', 'nullable': 'NO'},\n",
    "        'table_name': {'type': 'text', 'nullable': 'YES'},\n",
    "        'file_path': {'type': 'text', 'nullable': 'YES'},\n",
    "        'status': {'type': 'text', 'nullable': 'NO'},\n",
    "        'rows_loaded': {'type': 'bigint', 'nullable': 'YES'},\n",
    "        'started_at': {'type': 'timestamp with time zone', 'nullable': 'NO'},\n",
    "        'finished_at': {'type': 'timestamp with time zone', 'nullable': 'YES'},\n",
    "        'duration_sec': {'type': 'integer', 'nullable': 'YES'},\n",
    "        'message': {'type': 'text', 'nullable': 'YES'}\n",
    "    }\n",
    "    \n",
    "    # Verify each expected column\n",
    "    for col_name, expected in expected_columns.items():\n",
    "        assert col_name in column_dict, f\"Column '{col_name}' must exist\"\n",
    "        assert column_dict[col_name]['type'] == expected['type'], \\\n",
    "            f\"Column '{col_name}' should be {expected['type']}, got {column_dict[col_name]['type']}\"\n",
    "        assert column_dict[col_name]['nullable'] == expected['nullable'], \\\n",
    "            f\"Column '{col_name}' nullable mismatch\"\n",
    "\n",
    "def test_load_log_primary_key(db_cursor):\n",
    "    \"\"\"Verify id column is the primary key.\"\"\"\n",
    "    db_cursor.execute(\"\"\"\n",
    "        SELECT a.attname\n",
    "        FROM pg_index i\n",
    "        JOIN pg_attribute a ON a.attrelid = i.indrelid AND a.attnum = ANY(i.indkey)\n",
    "        WHERE i.indrelid = 'bronze.load_log'::regclass\n",
    "          AND i.indisprimary\n",
    "    \"\"\")\n",
    "    pk_columns = [row[0] for row in db_cursor.fetchall()]\n",
    "    assert pk_columns == ['id'], \"Primary key should be 'id' column only\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab82e12a",
   "metadata": {},
   "source": [
    "## Test 4: Index Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafae760",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ipytest -vv\n",
    "\n",
    "def test_load_log_indexes_exist(db_cursor):\n",
    "    \"\"\"Verify all expected indexes are created.\"\"\"\n",
    "    db_cursor.execute(\"\"\"\n",
    "        SELECT indexname\n",
    "        FROM pg_indexes\n",
    "        WHERE schemaname = 'bronze'\n",
    "          AND tablename = 'load_log'\n",
    "        ORDER BY indexname\n",
    "    \"\"\")\n",
    "    \n",
    "    indexes = [row[0] for row in db_cursor.fetchall()]\n",
    "    \n",
    "    # Expected indexes (excluding primary key index)\n",
    "    expected_indexes = [\n",
    "        'idx_load_log_duration',\n",
    "        'idx_load_log_file_path',\n",
    "        'idx_load_log_finished_at',\n",
    "        'idx_load_log_phase',\n",
    "        'idx_load_log_rows_loaded',\n",
    "        'idx_load_log_run_id',\n",
    "        'idx_load_log_started_at',\n",
    "        'idx_load_log_status',\n",
    "        'idx_load_log_table_name'\n",
    "    ]\n",
    "    \n",
    "    for idx_name in expected_indexes:\n",
    "        assert idx_name in indexes, f\"Index '{idx_name}' must exist\"\n",
    "    \n",
    "    # Verify we have at least 10 indexes (9 explicit + 1 PK)\n",
    "    assert len(indexes) >= 10, f\"Expected at least 10 indexes, found {len(indexes)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ea970f",
   "metadata": {},
   "source": [
    "## Test 5: Constraint Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81f4132",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ipytest -vv\n",
    "\n",
    "def test_load_log_check_constraints(db_cursor):\n",
    "    \"\"\"Verify CHECK constraints on status and phase columns.\"\"\"\n",
    "    db_cursor.execute(\"\"\"\n",
    "        SELECT conname, pg_get_constraintdef(oid) AS definition\n",
    "        FROM pg_constraint\n",
    "        WHERE conrelid = 'bronze.load_log'::regclass\n",
    "          AND contype = 'c'\n",
    "        ORDER BY conname\n",
    "    \"\"\")\n",
    "    \n",
    "    constraints = {row[0]: row[1] for row in db_cursor.fetchall()}\n",
    "    \n",
    "    # Verify status constraint\n",
    "    assert 'load_log_status_chk' in constraints, \"status CHECK constraint must exist\"\n",
    "    assert 'OK' in constraints['load_log_status_chk'], \"status constraint should include 'OK'\"\n",
    "    assert 'ERROR' in constraints['load_log_status_chk'], \"status constraint should include 'ERROR'\"\n",
    "    \n",
    "    # Verify phase constraint\n",
    "    assert 'load_log_phase_chk' in constraints, \"phase CHECK constraint must exist\"\n",
    "    phases = ['START', 'TRUNCATE', 'COPY', 'SEPARATOR', 'FINISH', 'ERROR']\n",
    "    for phase in phases:\n",
    "        assert phase in constraints['load_log_phase_chk'], \\\n",
    "            f\"phase constraint should include '{phase}'\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5b9ab9",
   "metadata": {},
   "source": [
    "## Test 6: Default Values and Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436affec",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ipytest -vv\n",
    "\n",
    "def test_load_log_id_sequence(db_cursor):\n",
    "    \"\"\"Verify id column uses a sequence (BIGSERIAL).\"\"\"\n",
    "    db_cursor.execute(\"\"\"\n",
    "        SELECT column_default\n",
    "        FROM information_schema.columns\n",
    "        WHERE table_schema = 'bronze'\n",
    "          AND table_name = 'load_log'\n",
    "          AND column_name = 'id'\n",
    "    \"\"\")\n",
    "    \n",
    "    default_value = db_cursor.fetchone()[0]\n",
    "    assert default_value is not None, \"id column should have a default value\"\n",
    "    assert 'nextval' in default_value, \"id should use a sequence\"\n",
    "\n",
    "def test_load_log_started_at_default(db_cursor):\n",
    "    \"\"\"Verify started_at has clock_timestamp() default.\"\"\"\n",
    "    db_cursor.execute(\"\"\"\n",
    "        SELECT column_default\n",
    "        FROM information_schema.columns\n",
    "        WHERE table_schema = 'bronze'\n",
    "          AND table_name = 'load_log'\n",
    "          AND column_name = 'started_at'\n",
    "    \"\"\")\n",
    "    \n",
    "    default_value = db_cursor.fetchone()[0]\n",
    "    assert default_value is not None, \"started_at should have a default value\"\n",
    "    assert 'clock_timestamp' in default_value.lower(), \"started_at should default to clock_timestamp()\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65bc0cc0",
   "metadata": {},
   "source": [
    "## Test 7: Integration Test - Insert and Verify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85525e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ipytest -vv\n",
    "\n",
    "def test_load_log_insert_and_query(db_cursor):\n",
    "    \"\"\"Test inserting a record and querying it back.\"\"\"\n",
    "    import uuid\n",
    "    \n",
    "    # Generate a unique run_id for this test\n",
    "    test_run_id = uuid.uuid4()\n",
    "    \n",
    "    # Insert a test record\n",
    "    db_cursor.execute(\"\"\"\n",
    "        INSERT INTO bronze.load_log (\n",
    "            run_id, phase, status, message\n",
    "        ) VALUES (\n",
    "            %s, 'START', 'OK', 'Test run from pytest'\n",
    "        )\n",
    "        RETURNING id, run_id, phase, status\n",
    "    \"\"\", (test_run_id,))\n",
    "    \n",
    "    result = db_cursor.fetchone()\n",
    "    assert result is not None, \"Insert should return a row\"\n",
    "    assert result[1] == test_run_id, \"run_id should match\"\n",
    "    assert result[2] == 'START', \"phase should be START\"\n",
    "    assert result[3] == 'OK', \"status should be OK\"\n",
    "    \n",
    "    # Clean up test data\n",
    "    db_cursor.execute(\"\"\"\n",
    "        DELETE FROM bronze.load_log \n",
    "        WHERE run_id = %s\n",
    "    \"\"\", (test_run_id,))\n",
    "    \n",
    "    print(f\"âœ… Successfully inserted and deleted test record with run_id: {test_run_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062edf54",
   "metadata": {},
   "source": [
    "## Summary: Run All Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62c6a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run all tests in this notebook\n",
    "ipytest.run('-vv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cddf3a2",
   "metadata": {},
   "source": [
    "## Manual Inspection Queries\n",
    "\n",
    "Use these queries to manually inspect the table structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7119495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect and display table structure\n",
    "conn = psycopg2.connect(**DB_CONFIG)\n",
    "\n",
    "# View all columns\n",
    "df_columns = pd.read_sql(\"\"\"\n",
    "    SELECT \n",
    "        column_name,\n",
    "        data_type,\n",
    "        is_nullable,\n",
    "        column_default\n",
    "    FROM information_schema.columns\n",
    "    WHERE table_schema = 'bronze'\n",
    "      AND table_name = 'load_log'\n",
    "    ORDER BY ordinal_position\n",
    "\"\"\", conn)\n",
    "\n",
    "print(\"\\nðŸ“Š bronze.load_log Columns:\")\n",
    "display(df_columns)\n",
    "\n",
    "# View all indexes\n",
    "df_indexes = pd.read_sql(\"\"\"\n",
    "    SELECT \n",
    "        indexname,\n",
    "        indexdef\n",
    "    FROM pg_indexes\n",
    "    WHERE schemaname = 'bronze'\n",
    "      AND tablename = 'load_log'\n",
    "    ORDER BY indexname\n",
    "\"\"\", conn)\n",
    "\n",
    "print(\"\\nðŸ“‡ bronze.load_log Indexes:\")\n",
    "display(df_indexes)\n",
    "\n",
    "# View constraints\n",
    "df_constraints = pd.read_sql(\"\"\"\n",
    "    SELECT \n",
    "        conname AS constraint_name,\n",
    "        contype AS constraint_type,\n",
    "        pg_get_constraintdef(oid) AS definition\n",
    "    FROM pg_constraint\n",
    "    WHERE conrelid = 'bronze.load_log'::regclass\n",
    "    ORDER BY conname\n",
    "\"\"\", conn)\n",
    "\n",
    "print(\"\\nðŸ”’ bronze.load_log Constraints:\")\n",
    "display(df_constraints)\n",
    "\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}